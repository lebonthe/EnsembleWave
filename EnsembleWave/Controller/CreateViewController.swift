//
//  CreateViewController.swift
//  EnsembleWave
//
//  Created by Min Hu on 2024/4/9.
//
import UIKit
import AVFoundation // ÈåÑÂΩ±
import AVKit // Êí≠ÊîæÂΩ±ÂÉè access to AVPlayer
import Photos // ÂÑ≤Â≠òÂΩ±ÂÉè
import MediaPlayer // ÊîπËÆäÈü≥Èáè
import VideoTrim // Ë£ÅÂàáÂΩ±Áâá
import Vision // ÊâãÂã¢
import PhotosUI // ÈÅ∏ÂèñÁõ∏Á∞øÂΩ±Áâá
import Lottie // ÂãïÁï´
import SwiftEntryKit
class CreateViewController: UIViewController {
    @IBOutlet weak var containerView: UIView!
    @IBOutlet weak var cameraButton: UIButton!
    @IBOutlet weak var stretchScreenButton: UIButton!
    @IBOutlet weak var shrinkScreenButton: UIButton!
    var style = 0
    var length: Int = 15
    var devices = [AVCaptureDevice]()
    var isFrontCamera: Bool = true {
        didSet {
            currentDevice = isFrontCamera ? devices[0] : devices[1]
            guard let newInput = try? AVCaptureDeviceInput(device: currentDevice) else {
                print("Unable to create input from the device.")
                return
            }
            configureSessionWithNewInput(newInput)
        }
    }
    let captureSession = AVCaptureSession()
    var currentDevice: AVCaptureDevice!
    var videoFileOutput: AVCaptureMovieFileOutput!
    var cameraPreviewLayer: AVCaptureVideoPreviewLayer?
    var isRecording = false
    var players: [AVPlayer] = []
    var playerLayers: [AVPlayerLayer] = []
    var replayButton = UIButton()
    @IBOutlet private var containerViewLeadingConstraint: NSLayoutConstraint!
    @IBOutlet private var containerViewTrailingConstraint: NSLayoutConstraint!
    @IBOutlet weak var containerViewRatio: NSLayoutConstraint!
    @IBOutlet weak var headphoneAlertLabel: UILabel!
    var videoViews: [UIView] = []
    let line = UIView()
    var chooseViewButtons = [UIButton]()
    let countdownButton = UIButton() // ÈñãÂßãÂâçÁöÑÂÄíÊï∏Ë®àÊôÇ
    let cameraPositionButton = UIButton()
    @IBOutlet weak var postProductionView: UIView!
    var outputFileURL: URL?
    var currentRecordingIndex = 0
    
    var videoURLs: [URL] = []
    var audioURLs: [URL] = []
    var playerVolume: Float = 0.5
    var previousVolume: Float = 0.5
    @IBOutlet weak var trimView: TrimView!
    var endTimeObservers: [AVPlayer: Any] = [:]
    private var isPlaying = false
    private var preset: String?
    var endTimeObserver: Any?
    private let recordingTopView: UIView = {
        let view = UIView()
        view.translatesAutoresizingMaskIntoConstraints = false
        return view
    }()
    private let countdownLabel: UILabel = {
        let label = UILabel()
        label.translatesAutoresizingMaskIntoConstraints = false
        return label
    }()
    var countdownTimer: Timer?
    var videoViewHasContent: [Int: Bool] = [:]
    lazy var tapGesture00 = UITapGestureRecognizer(target: self, action: #selector(videoViewTapped(_:)))
    lazy var tapGesture01 = UITapGestureRecognizer(target: self, action: #selector(videoViewTapped(_:)))
    var countBeforeRecording: Bool = true // ‰ΩøÁî®ËÄÖÈªûÈÅ∏Áõ∏Ê©üÔºåÊ±∫ÂÆöË¶Å‰∏çË¶ÅÂÄíÊï∏Ë®àÊôÇ
    let countingImages = ["5.circle.fill", "4.circle.fill", "3.circle.fill", "2.circle.fill", "1.circle.fill"]
    var currentImageIndex = 0
    var countdownImageView: UIImageView = {
        let imageView = UIImageView()
        imageView.translatesAutoresizingMaskIntoConstraints = false
        return imageView
    }()
    var timerBeforePlay: Timer?
    var handPoseRequest = VNDetectHumanHandPoseRequest()
    var useHandPoseStartRecording: Bool = false
    var isHeadphoneConnected: Bool = false {
        didSet {
            headphoneAlertLabel.isHidden = isHeadphoneConnected
            print("ËÄ≥Ê©üÂ∑≤ÈÄ£Êé•:\(isHeadphoneConnected)")
        }
    }
    @IBOutlet weak var albumButton: UIButton!
    @IBOutlet weak var musicButton: UIButton!
    var selectedMusic: MusicType?
    var audioPlayer: AVAudioPlayer?
    var musicPlayer: MPMusicPlayerController?
    var animView: LottieAnimationView?
    var ensembleVideoURL: String?
    var ensembleUserID: String?
    var duration: Int?
    lazy var handPoseButton = UIButton()
    var restingHand = true
    @IBOutlet weak var cameraBottomView: UIView!
    var video0URL: URL?
    var video1URL: URL?
    override func viewDidLoad() {
        super.viewDidLoad()
        print("===== CreateViewController viewDidLoad =====")
        print("length:\(length)")
        print("viewDidLoad ensembleVideoURL:\(ensembleVideoURL ?? "no ensembleVideoURL")")
        videoURLs.removeAll()
        setupUI(style)
        setupReplayButton()
        bookEarphoneState()
        configurePlayersAndAddObservers()
        clearTemporaryVideos()
    }
    override func viewWillAppear(_ animated: Bool) {
        super.viewWillAppear(animated)
        print("===== CreateViewController viewWillAppear =====")
        print("style:\(style)")
        getCurrentSystemVolume()
    }
    override func viewDidLayoutSubviews() {
        super.viewDidLayoutSubviews()
        print("===== CreateViewController viewDidLayoutSubviews =====")
    }
    func stopAnim() {
        animView?.stop()
        animView?.removeFromSuperview()
        animView = nil
    }
    override func viewWillDisappear(_ animated: Bool) {
//        stopAnim()
        recordingTopView.isHidden = true
        //        recordingTopView.removeFromSuperview()
        for player in players {
            NotificationCenter.default.removeObserver(self, name: .AVPlayerItemDidPlayToEndTime, object: player.currentItem)
        }
        AVAudioSession.sharedInstance().removeObserver(self, forKeyPath: "outputVolume")
        for (player, observer) in endTimeObservers {
            player.removeTimeObserver(observer)
        }
        endTimeObservers.removeAll()
        for player in players {
            player.pause()
            player.replaceCurrentItem(with: nil)
        }
        musicPlayer?.stop()
        musicPlayer = nil
        audioPlayer?.stop()
        audioPlayer = nil
        NotificationCenter.default.removeObserver(self, name: AVAudioSession.routeChangeNotification, object: nil)
        for layer in playerLayers {
            layer.removeFromSuperlayer()
        }
        replayButton.isHidden = true
    }
    override func viewDidDisappear(_ animated: Bool) {
        super.viewDidDisappear(animated)
        print("===== CreateViewController viewDidDisappear =====")
        //        dchCheckDeallocation()
    }
    override func viewDidAppear(_ animated: Bool) {
        print("===== CreateViewController viewDidAppear =====")
        if ensembleVideoURL != nil && style == 1 {
            chooseView(chooseViewButtons[0])
            chooseViewButtons[1].isHidden = true
            videoViewHasContent[1] = true
            videoViews[1].addGestureRecognizer(tapGesture01)
        }
    }
    @objc func preparedToShare() {
        mergingAnimation()
        let asset = AVURLAsset(url: videoURLs[currentRecordingIndex])
        let keys = ["tracks"]
        
        asset.loadValuesAsynchronously(forKeys: keys) {
                var error: NSError?
                let status = asset.statusOfValue(forKey: "tracks", error: &error)
                if status == .loaded {
                    if asset.tracks(withMediaType: .video).isEmpty {
                        print("asset ‰∏≠Ê≤íÊúâÂΩ±Áâá tracks")
                    } else {
                        DispatchQueue.main.async {
                            self.continuePreparedToShare(with: asset)
                        }
                    }
                } else {
                    print("Ë≥áÊ∫êÁöÑËªåÈÅìÂä†ËºâÊú™ÊàêÂäü: \(error?.localizedDescription ?? "Êú™Áü•ÈåØË™§")")
                }
        }
    }
    func setupShareButton() {
        trimView.isHidden = true
        let shareButton = UIBarButtonItem(title: "ÂàÜ‰∫´", style: .plain, target: self, action: #selector(pushSharePage(_:)))
        self.navigationItem.rightBarButtonItem = shareButton
        self.navigationItem.leftBarButtonItem = nil
    }
    func continuePreparedToShare(with asset: AVAsset) {
        setupShareButton()
        
        let startTime = trimView.videoTrim.startTime
        let endTime = trimView.videoTrim.endTime
        
        if let outputURL = getVideoURL(for: currentRecordingIndex) {
            print("ÈñãÂßãÂ∞éÂá∫Âà∞: \(outputURL)")
            do {
                // Â¶ÇÊûúÈÄôÂÄã‰ΩçÁΩÆÂ∑≤Á∂ìÊúâÊ™îÊ°àÂ≠òÂú®ÔºåÂ∞éÂá∫ÊúÉÂ§±ÊïóÔºåÂõ†Ê≠§Ë¶ÅÂÖàÂà™Èô§
                try FileManager.default.removeItem(at: outputURL)
            } catch {
                print("Ê∏ÖÈô§ËàäÊ™îÊ°àÂ§±Êïó: \(error.localizedDescription)")
            }
            exportCroppedVideo(asset: asset, startTime: startTime, endTime: endTime, outputURL: outputURL) { success in
                DispatchQueue.main.async {
                    if success {
                        let playerItem = AVPlayerItem(url: outputURL)
                        self.players[self.currentRecordingIndex].replaceCurrentItem(with: playerItem)
                        self.players[self.currentRecordingIndex].seek(to: CMTime.zero)
                        self.players[self.currentRecordingIndex].play()
                        self.replayVideo()
                        self.setupEndTimeObserver(for: self.players[self.currentRecordingIndex], startTime: startTime, endTime: endTime)
                        self.setupObserversForPlayerItem(playerItem, with: self.players[self.currentRecordingIndex])
                        print("Ë£ÅÂâ™ÂíåÂ∞éÂá∫ÊàêÂäü")
                        self.videoViewHasContent[self.currentRecordingIndex] = true
                        if self.style > 0 {
                            let otherIndex = self.currentRecordingIndex == 0 ? 1 : 0
                            if let hasContent = self.videoViewHasContent[otherIndex], hasContent {
                                if otherIndex == 0 {
                                    self.videoViews[otherIndex].addGestureRecognizer(self.tapGesture00)
                                } else if otherIndex == 1 {
                                    self.videoViews[otherIndex].addGestureRecognizer(self.tapGesture01)
                                }
                                print("preparedToShare self.videoViewHasContent[otherIndex]:\(hasContent)")
                            } else {
                                self.chooseViewButtons[otherIndex].isHidden = false
                                print("preparedToShare self.videoViewHasContent[otherIndex]: no")
                            }
//                            if self.videoViewHasContent[otherIndex] == false {
//                                self.chooseViewButtons[otherIndex].isHidden = false
//                            } else {
//                                if otherIndex == 0 {
//                                    self.videoViews[otherIndex].addGestureRecognizer(self.tapGesture00)
//                                } else if otherIndex == 1 {
//                                    self.videoViews[otherIndex].addGestureRecognizer(self.tapGesture01)
//                                }
//                            }
                            
                        }
                        if self.currentRecordingIndex == 0 {
                            self.videoViews[self.currentRecordingIndex].addGestureRecognizer(self.tapGesture00)
                            self.videoViews[0].isUserInteractionEnabled = true
                        } else if self.currentRecordingIndex == 1 {
                            self.videoViews[self.currentRecordingIndex].addGestureRecognizer(self.tapGesture01)
                            self.videoViews[1].isUserInteractionEnabled = true
                        }
                        print("videoViews[0].subviews:\(self.videoViews[0].subviews)")
                        let durationInSeconds = CMTimeGetSeconds(asset.duration)
                        self.duration = Int(durationInSeconds.rounded())
                        print("ÂÑ≤Â≠òÁöÑÂΩ±ÁâáÈï∑Â∫¶ÁÇ∫: \(self.duration ?? 0) Áßí")
                        self.stopAnim()
                    } else {
                        print("Ë£ÅÂâ™ÂíåÂ∞éÂá∫Â§±Êïó")
                        self.stopAnim()
                        CustomFunc.customAlert(title: "Ë£ÅÂâ™ÂíåÂ∞éÂá∫Â§±Êïó", message: "ÂÜçË©¶‰∏ÄÊ¨°", vc: self, actionHandler: nil)
                    }
                }
            }
        }
    }
    
    @objc func recordAgain() {
        stopAllVideos()
        //        let cameraPositionButton = UIBarButtonItem(image: UIImage(systemName: "arrow.triangle.2.circlepath.camera"), style: .plain, target: self, action: #selector(toggleCameraPosition(_:)))
        //        self.navigationItem.rightBarButtonItem = cameraPositionButton
        if style == 0 {
            startToRecordingView()
        } else {
            chooseView(chooseViewButtons[currentRecordingIndex])
            chooseViewButtons[currentRecordingIndex].isHidden = true
        }
        self.navigationItem.leftBarButtonItem = nil
        trimView.isHidden = true
        stopCountdownTimer()
        self.countdownLabel.text = self.timeFormatter(sec: self.length)
        self.clearVideoView(for: self.currentRecordingIndex)
//        self.prepareRecording(for: self.currentRecordingIndex)
        if useHandPoseStartRecording {
            addGestureRecognitionToSession()
        } else {
            //            disableGestureRecognition()
        }
    }
    private func setupTrimView() {
        stopCountdownTimer()
        postProductionView.isHidden = false
        if style > 0 {
            let otherIndex = currentRecordingIndex == 0 ? 1 : 0
            chooseViewButtons[otherIndex].isHidden = true
        }
        let trimOKButton = UIBarButtonItem(image: UIImage(systemName: "checkmark.circle.fill"), style: .plain, target: self, action: #selector(preparedToShare))
        let trimCancelButton = UIBarButtonItem(image: UIImage(systemName: "xmark.circle.fill"), style: .plain, target: self, action: #selector(recordAgain))
        self.navigationItem.rightBarButtonItem = trimOKButton
        self.navigationItem.leftBarButtonItem = trimCancelButton
        var videoFileURL: URL?
        if style == 1 && ensembleVideoURL != nil {
            guard let url = URL(string: ensembleVideoURL!) else {
                print("no ensembleVideoURL")
                return
            }
            videoFileURL = url
        } else {
            if currentRecordingIndex == 0 && video0URL != nil {
                if let video0URL = video0URL {
                    videoFileURL = video0URL
                }
            } else if currentRecordingIndex == 1 && video1URL != nil {
                if let video1URL = video1URL {
                    videoFileURL = video1URL
                }
            } else {
                guard let url = getVideoURL(for: currentRecordingIndex) else {
                    print("Âú® setupTrimView ÂÖß getVideoURL Â§±Êïó")
                    return
                }
                videoFileURL = url
            }
        }
        guard let videoFileURL = videoFileURL else {
            return
        }
        
        let asset = AVAsset(url: videoFileURL)
        trimView.configure(with: asset)
        trimView.isHidden = false
        trimView.videoTrim.delegate = self
    }
    
    deinit {
        print("===== Enter CreatViewController deinit =====")
        withUnsafeBytes(of: &(players)) { (point) -> Void in
            print("players Âú®Ë®òÊÜ∂È´îÁöÑ‰ΩçÁΩÆ:\(point)")
        }
        
        print("===== Leave CreatViewController deinit =====")
        withUnsafeBytes(of: &(players)) { (point) -> Void in
            print("players Âú®Ë®òÊÜ∂È´îÁöÑ‰ΩçÁΩÆ:\(point)")
        }
        clearTemporaryFiles()
    }
    func clearTemporaryFiles() {
        let tempDirectoryPath = NSTemporaryDirectory()
        
        do {
            let fileManager = FileManager.default
            let tempFiles = try fileManager.contentsOfDirectory(atPath: tempDirectoryPath)
            for file in tempFiles {
                let filePath = (tempDirectoryPath as NSString).appendingPathComponent(file)
                try fileManager.removeItem(atPath: filePath)
            }
            print("Temporary files are deleted.")
        } catch {
            print("Failed to delete temporary files: \(error)")
        }
    }
    func setupUI(_ style: Int) {
        //        headphoneAlertLabel.textColor = CustomColor.red
        let headphoneText = "Headphones are not detected, sound cannot be played during recording!"
        headphoneAlertLabel.attributedText = attributedTextForm(content: headphoneText, size: 15, kern: 0, color: CustomColor.red ?? .red)
        headphoneAlertLabel.numberOfLines = 0
        cameraButton.tintColor = CustomColor.red
        albumButton.tintColor = .white
        musicButton.tintColor = .white
        stretchScreenButton.tintColor = .white
        shrinkScreenButton.tintColor = .white
        view.backgroundColor = .black
        trimView.isHidden = true
        videoViews.forEach { $0.removeFromSuperview() }
        videoViews.removeAll()
        players.removeAll()
        playerLayers.removeAll()
        //        let cameraPositionButton = UIBarButtonItem(image: UIImage(systemName: "arrow.triangle.2.circlepath.camera"), style: .plain, target: self, action: #selector(toggleCameraPosition(_:)))
        //        self.navigationItem.rightBarButtonItem = cameraPositionButton
        print("style in setupUI: \(style)")
        containerView.layer.borderColor = UIColor.white.cgColor
        containerView.layer.borderWidth = 2
        containerView.layer.cornerRadius = 10
        containerView.clipsToBounds = true
        containerView.translatesAutoresizingMaskIntoConstraints = false
        containerViewLeadingConstraint.constant = 16
        containerViewTrailingConstraint.constant = -16
        NSLayoutConstraint.activate([
            containerView.topAnchor.constraint(equalTo: view.safeAreaLayoutGuide.topAnchor, constant: 50)
        ])
        for _ in 0...style {
            let videoView = UIView()
            videoView.backgroundColor = CustomColor.mattBlack
            containerView.addSubview(videoView)
            videoViews.append(videoView)
        }
        trimView.translatesAutoresizingMaskIntoConstraints = false
        videoViews[0].translatesAutoresizingMaskIntoConstraints = false
        NSLayoutConstraint.activate([
            trimView.bottomAnchor.constraint(equalTo: view.safeAreaLayoutGuide.bottomAnchor),
            trimView.heightAnchor.constraint(equalToConstant: 200),
            trimView.leadingAnchor.constraint(equalTo: view.leadingAnchor),
            trimView.trailingAnchor.constraint(equalTo: view.trailingAnchor)
        ])
        
        if style == 0 {
            videoViewHasContent[0] = false
            videoViews[0].tag = 0
            if let hasContent = videoViewHasContent[0], hasContent {
                videoViews[0].addGestureRecognizer(tapGesture00)
            }
            videoViews[0].isUserInteractionEnabled = true
            videoViews[0].frame = containerView.bounds
            let startButton = UIButton()
            chooseViewButtons.append(startButton)
            videoViews[0].addSubview(chooseViewButtons[0])
            chooseViewButtons[0].setBackgroundImage(UIImage(systemName: "plus"), for: .normal)
            chooseViewButtons[0].translatesAutoresizingMaskIntoConstraints = false
            chooseViewButtons[0].tintColor = .white
            chooseViewButtons[0].addTarget(self, action: #selector(startToRecordingView), for: .touchDown)
            NSLayoutConstraint.activate([
                videoViews[0].topAnchor.constraint(equalTo: containerView.topAnchor),
                videoViews[0].leadingAnchor.constraint(equalTo: containerView.leadingAnchor),
                videoViews[0].trailingAnchor.constraint(equalTo: containerView.trailingAnchor),
                videoViews[0].bottomAnchor.constraint(equalTo: containerView.bottomAnchor),
                chooseViewButtons[0].centerXAnchor.constraint(equalTo: videoViews[0].centerXAnchor),
                chooseViewButtons[0].centerYAnchor.constraint(equalTo: videoViews[0].centerYAnchor),
                chooseViewButtons[0].widthAnchor.constraint(equalToConstant: 40),
                chooseViewButtons[0].heightAnchor.constraint(equalToConstant: 40)
            ])
        } else if style == 1 {
            videoViewHasContent[0] = false
            videoViewHasContent[1] = false
            for (index, videoView) in videoViews.enumerated() {
                videoView.tag = index
                videoView.isUserInteractionEnabled = true
                if let hasContent = videoViewHasContent[index], hasContent {
                    if index == 0 {
                        videoView.addGestureRecognizer(tapGesture00)
                    } else if index == 1 {
                        videoView.addGestureRecognizer(tapGesture01)
                    }
                }
            }
            line.backgroundColor = .white
            containerView.addSubview(line)
            
            let button0 = UIButton()
            let button1 = UIButton()
            chooseViewButtons.append(button0)
            chooseViewButtons.append(button1)
            containerView.addSubview(chooseViewButtons[0])
            containerView.addSubview(chooseViewButtons[1])
            chooseViewButtons[0].setBackgroundImage(UIImage(systemName: "plus"), for: .normal)
            chooseViewButtons[1].setBackgroundImage(UIImage(systemName: "plus"), for: .normal)
            chooseViewButtons[0].translatesAutoresizingMaskIntoConstraints = false
            chooseViewButtons[1].translatesAutoresizingMaskIntoConstraints = false
            chooseViewButtons[0].tintColor = .white
            chooseViewButtons[1].tintColor = .white
            videoViews[1].translatesAutoresizingMaskIntoConstraints = false
            line.translatesAutoresizingMaskIntoConstraints = false
            
            NSLayoutConstraint.activate([
                line.widthAnchor.constraint(equalToConstant: 2),
                line.centerXAnchor.constraint(equalTo: containerView.centerXAnchor),
                line.topAnchor.constraint(equalTo: containerView.topAnchor),
                line.bottomAnchor.constraint(equalTo: containerView.bottomAnchor),
                videoViews[0].topAnchor.constraint(equalTo: containerView.topAnchor),
                videoViews[0].leadingAnchor.constraint(equalTo: containerView.leadingAnchor),
                videoViews[0].trailingAnchor.constraint(equalTo: line.leadingAnchor),
                videoViews[0].bottomAnchor.constraint(equalTo: containerView.bottomAnchor),
                videoViews[1].topAnchor.constraint(equalTo: containerView.topAnchor),
                videoViews[1].leadingAnchor.constraint(equalTo: line.trailingAnchor),
                videoViews[1].trailingAnchor.constraint(equalTo: containerView.trailingAnchor),
                videoViews[1].bottomAnchor.constraint(equalTo: containerView.bottomAnchor),
                chooseViewButtons[0].centerXAnchor.constraint(equalTo: videoViews[0].centerXAnchor),
                chooseViewButtons[0].centerYAnchor.constraint(equalTo: videoViews[0].centerYAnchor),
                chooseViewButtons[0].widthAnchor.constraint(equalToConstant: 40),
                chooseViewButtons[0].heightAnchor.constraint(equalToConstant: 40),
                chooseViewButtons[1].centerXAnchor.constraint(equalTo: videoViews[1].centerXAnchor),
                chooseViewButtons[1].centerYAnchor.constraint(equalTo: videoViews[1].centerYAnchor),
                chooseViewButtons[1].widthAnchor.constraint(equalToConstant: 40),
                chooseViewButtons[1].heightAnchor.constraint(equalToConstant: 40)
            ])
            for chooseViewButton in chooseViewButtons {
                chooseViewButton.addTarget(self, action: #selector(chooseView(_:)), for: .touchDown)
            }
        }
        cameraButton.translatesAutoresizingMaskIntoConstraints = false
        stretchScreenButton.translatesAutoresizingMaskIntoConstraints = false
        shrinkScreenButton.translatesAutoresizingMaskIntoConstraints = false
        postProductionView.translatesAutoresizingMaskIntoConstraints = false
        albumButton.translatesAutoresizingMaskIntoConstraints = false
        musicButton.translatesAutoresizingMaskIntoConstraints = false
        postProductionView.backgroundColor = .black
        
        NSLayoutConstraint.activate([
            cameraButton.centerXAnchor.constraint(equalTo: view.centerXAnchor),
            cameraButton.bottomAnchor.constraint(equalTo: view.safeAreaLayoutGuide.bottomAnchor, constant: -8),
            cameraButton.heightAnchor.constraint(equalToConstant: 60),
            cameraButton.widthAnchor.constraint(equalToConstant: 60),
            albumButton.centerYAnchor.constraint(equalTo: cameraButton.centerYAnchor),
            albumButton.leadingAnchor.constraint(equalTo: view.leadingAnchor, constant: 15),
            albumButton.heightAnchor.constraint(equalTo: cameraButton.heightAnchor, multiplier: 0.6),
            albumButton.widthAnchor.constraint(equalTo: cameraButton.widthAnchor, multiplier: 0.6),
            musicButton.leadingAnchor.constraint(equalTo: albumButton.trailingAnchor, constant: 15),
            musicButton.centerYAnchor.constraint(equalTo: cameraButton.centerYAnchor),
            musicButton.heightAnchor.constraint(equalTo: cameraButton.heightAnchor, multiplier: 0.6),
            musicButton.widthAnchor.constraint(equalTo: cameraButton.widthAnchor, multiplier: 0.6),
            stretchScreenButton.trailingAnchor.constraint(equalTo: view.trailingAnchor, constant: -15),
            stretchScreenButton.centerYAnchor.constraint(equalTo: cameraButton.centerYAnchor),
            stretchScreenButton.heightAnchor.constraint(equalTo: cameraButton.heightAnchor, multiplier: 0.5),
            stretchScreenButton.widthAnchor.constraint(equalTo: cameraButton.widthAnchor, multiplier: 0.5),
            shrinkScreenButton.trailingAnchor.constraint(equalTo: view.trailingAnchor, constant: -15),
            shrinkScreenButton.centerYAnchor.constraint(equalTo: cameraButton.centerYAnchor),
            shrinkScreenButton.heightAnchor.constraint(equalTo: cameraButton.heightAnchor, multiplier: 0.5),
            shrinkScreenButton.widthAnchor.constraint(equalTo: cameraButton.widthAnchor, multiplier: 0.5),
            postProductionView.bottomAnchor.constraint(equalTo: view.safeAreaLayoutGuide.bottomAnchor, constant: 8),
            postProductionView.heightAnchor.constraint(equalToConstant: 80),
            postProductionView.leadingAnchor.constraint(equalTo: view.leadingAnchor),
            postProductionView.trailingAnchor.constraint(equalTo: view.trailingAnchor)
        ])
        shrinkScreenButton.isHidden = true
        view.addSubview(countdownImageView)
        countdownImageView.layer.cornerRadius = 50
        countdownImageView.clipsToBounds = true
        countdownImageView.tintColor = CustomColor.red
        countdownImageView.backgroundColor = .white
        NSLayoutConstraint.activate([
            countdownImageView.centerXAnchor.constraint(equalTo: view.centerXAnchor),
            countdownImageView.centerYAnchor.constraint(equalTo: view.centerYAnchor),
            countdownImageView.heightAnchor.constraint(equalToConstant: 100),
            countdownImageView.widthAnchor.constraint(equalToConstant: 100)
        ])
        countdownImageView.isHidden = true
    }
    @objc func videoViewTapped(_ sender: UITapGestureRecognizer) {
        guard let view = sender.view else {
            print("videoView sender ÂèñÂæóÂ§±Êïó")
            return
        }
        print("view:\(view)")
        
        let index = view.tag
        print("index:\(index)")
        let controller = UIAlertController(title: "ÈÅ∏ÂèñÂΩ±Áâá", message: nil, preferredStyle: .alert)
        let deleteaAndRecordAction = UIAlertAction(title: "Âà™Èô§‰∏¶ÈáçÈåÑ", style: .default) {  [weak self] action in
            guard let self = self else { return }
            self.clearVideoView(for: index)
            self.prepareRecording(for: index)
        }
        
        let cancelAction = UIAlertAction(title: "ÂèñÊ∂à", style: .cancel)
        controller.addAction(deleteaAndRecordAction)
        controller.addAction(cancelAction)
        
        present(controller, animated: true)
    }
    func timeFormatter(sec: Int) -> String {
        let formatter = DateComponentsFormatter()
        formatter.unitsStyle = .abbreviated
        let second: TimeInterval = Double(sec)
        guard let remainingTime = formatter.string(from: second) else {
            fatalError("ÊôÇÈñìËΩâÊèõÂ§±Êïó")
        }
        print("remainingTime: \(remainingTime)")
        return "- \(remainingTime)"
    }
    func startCountdownTimer() {
        var remainingTime = length
        countdownTimer = Timer.scheduledTimer(withTimeInterval: 1.0, repeats: true){ [weak self] _ in
            guard let self = self else { return }
            remainingTime -= 1
            updateCountdownLabel(remainingTime)
            if remainingTime == 0 {
                stopCountdownTimer()
                capture(sender: cameraButton)
            }
        }
    }
    func stopCountdownTimer() {
        countdownTimer?.invalidate()
        countdownTimer = nil
        timerBeforePlay?.invalidate()
        timerBeforePlay = nil
    }
    func updateCountdownLabel(_ remainingTime: Int) {
        //        countdownLabel.text = timeFormatter(sec: remainingTime)
        countdownLabel.attributedText = attributedTextForm(content: timeFormatter(sec: remainingTime), size: 22, kern: 0, color: CustomColor.red ?? .red)
    }
    func launchTrimTopView() {
        guard navigationController != nil else {
            print("There is no navigation controller")
            return
        }
        recordingTopView.isHidden = true
        //        recordingTopView.removeFromSuperview()
        setupTrimView()
    }
    func setupRecordingTopView() {
        guard let navigationController = navigationController else {
            print("There is no navigation controller")
            return
        }
        countBeforeRecording = true
        useHandPoseStartRecording = false
        if let navigationController = self.navigationController, !navigationController.view.subviews.contains(recordingTopView) {
            navigationController.view.addSubview(recordingTopView)
        }
        //        navigationController.view.addSubview(recordingTopView)
        recordingTopView.isHidden = false
        cameraPositionButton.setBackgroundImage(UIImage(systemName: "arrow.triangle.2.circlepath.camera"), for: .normal)
        cameraPositionButton.tintColor = .white
        cameraPositionButton.addTarget(self, action: #selector(toggleCameraPosition), for: .touchDown)
        let cancelButton = UIButton()
        cancelButton.setBackgroundImage(UIImage(systemName: "xmark"), for: .normal)
        cancelButton.tintColor = .white
        cancelButton.addTarget(self, action: #selector(cancelRecording), for: .touchDown)
        cameraPositionButton.translatesAutoresizingMaskIntoConstraints = false
        cancelButton.translatesAutoresizingMaskIntoConstraints = false
        recordingTopView.translatesAutoresizingMaskIntoConstraints = false
        recordingTopView.addSubview(cameraPositionButton)
        recordingTopView.addSubview(cancelButton)
        recordingTopView.addSubview(countdownLabel)
        recordingTopView.backgroundColor = .black
        updateCountdownLabel(length)
        //        countdownLabel.textColor = CustomColor.red
        let buttonSize = 28.0
        NSLayoutConstraint.activate([
            recordingTopView.topAnchor.constraint(equalTo: navigationController.view.topAnchor, constant: 30),
            recordingTopView.leadingAnchor.constraint(equalTo: navigationController.view.leadingAnchor),
            recordingTopView.trailingAnchor.constraint(equalTo: navigationController.view.trailingAnchor),
            recordingTopView.heightAnchor.constraint(equalToConstant: 50),
            countdownLabel.centerXAnchor.constraint(equalTo: recordingTopView.centerXAnchor),
            countdownLabel.centerYAnchor.constraint(equalTo: recordingTopView.centerYAnchor),
            countdownLabel.heightAnchor.constraint(equalToConstant: buttonSize),
            cameraPositionButton.centerYAnchor.constraint(equalTo: recordingTopView.centerYAnchor),
            cameraPositionButton.trailingAnchor.constraint(equalTo: recordingTopView.trailingAnchor, constant: -16),
            cameraPositionButton.heightAnchor.constraint(equalToConstant: buttonSize),
            cameraPositionButton.widthAnchor.constraint(equalToConstant: buttonSize),
            cancelButton.centerYAnchor.constraint(equalTo: recordingTopView.centerYAnchor),
            cancelButton.leadingAnchor.constraint(equalTo: recordingTopView.leadingAnchor, constant: 16),
            cancelButton.heightAnchor.constraint(equalToConstant: buttonSize),
            cancelButton.widthAnchor.constraint(equalToConstant: buttonSize)
        ])
        // ÈñãÂßãÂâçÁöÑÂÄíÊï∏Ë®àÊôÇ
        countdownButton.translatesAutoresizingMaskIntoConstraints = false
        countdownButton.setBackgroundImage(UIImage(systemName: "clock.badge.checkmark"), for: .normal)
        countdownButton.setBackgroundImage(UIImage(systemName: "clock.badge.xmark"), for: .selected)
        countdownButton.tintColor = .white
        countdownButton.isSelected = !countBeforeRecording
        recordingTopView.addSubview(countdownButton)
        countdownButton.addTarget(self, action: #selector(changeCountdownMode(_:)), for: .touchDown)
        NSLayoutConstraint.activate([
            countdownButton.centerYAnchor.constraint(equalTo: recordingTopView.centerYAnchor),
            countdownButton.trailingAnchor.constraint(equalTo: cameraPositionButton.leadingAnchor, constant: -16),
            countdownButton.heightAnchor.constraint(equalToConstant: buttonSize),
            countdownButton.widthAnchor.constraint(equalToConstant: buttonSize)
        ])
        
        handPoseButton.translatesAutoresizingMaskIntoConstraints = false
        //        handPoseButton.setTitle("ü§ò", for: .normal)
        handPoseButton.setTitle("üôÖ‚Äç‚ôÄÔ∏è", for: .normal)
        //        handPoseButton.isSelected = !useHandPoseStartRecording
        recordingTopView.addSubview(handPoseButton)
        handPoseButton.addTarget(self, action: #selector(changeHandPoseMode(_:)), for: .touchDown)
        NSLayoutConstraint.activate([
            handPoseButton.centerYAnchor.constraint(equalTo: recordingTopView.centerYAnchor),
            handPoseButton.trailingAnchor.constraint(equalTo: countdownButton.leadingAnchor, constant: -16),
            handPoseButton.heightAnchor.constraint(equalToConstant: buttonSize),
            handPoseButton.widthAnchor.constraint(equalToConstant: buttonSize)
        ])
        
    }
    @objc func changeHandPoseMode(_ sender: UIButton) {
        if handPoseButton.title(for: .normal) == "üôÖ‚Äç‚ôÄÔ∏è" {
            handPoseButton.setTitle("ü§ò", for: .normal)
            addGestureRecognitionToSession()
            
        } else {
            handPoseButton.setTitle("üôÖ‚Äç‚ôÄÔ∏è", for: .normal)
            disableGestureRecognition()
        }
        useHandPoseStartRecording.toggle()
        //        sender.isSelected = !useHandPoseStartRecording
        //        if useHandPoseStartRecording {
        //            addGestureRecognitionToSession()
        //        } else {
        //            disableGestureRecognition()
        //        }
    }
    
    @objc func changeCountdownMode(_ sender: UIButton) {
        countBeforeRecording.toggle()
        sender.isSelected = !countBeforeRecording
        if !countBeforeRecording {
            stopCountdwonBeforeRecording()
        }
        print("is countBeforeRecording:\(countBeforeRecording)")
    }
    // ÊåâÂ∑¶‰∏äËßíx
    @objc func cancelRecording() {
        resetView()
    }
    func configure(for style: Int) {
        do {
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.playAndRecord, mode: .default, options: [.mixWithOthers, .allowBluetooth, .defaultToSpeaker])
            try audioSession.setActive(true)
            print("Audio session is set to allow mixing with other apps.")
        } catch {
            print("Failed to set audio session category: \(error)")
        }
        if captureSession.isRunning {
            captureSession.stopRunning()
        }
        if style == 1 && players.count > 2 {
            players = Array(players.prefix(2))
        }
        
        for index in 0...style {
            if index == 1 && ensembleVideoURL != nil {
                guard let url = URL(string: ensembleVideoURL!) else {
                    print("no ensembleVideoURL")
                    return
                }
                print("ensembleVideoURL:\(url)")
                let player = AVPlayer(url: url)
                if players.count <= index {
                    players.append(player)
                } else {
                    players[index] = player
                }
                if let currentItem = player.currentItem {
                    setupObserversForPlayerItem(currentItem, with: player)
                }
                let playerLayer = AVPlayerLayer(player: player)
                playerLayer.frame = videoViews[index].bounds
                playerLayer.videoGravity = .resizeAspectFill
                videoViews[index].layer.addSublayer(playerLayer)
                if playerLayers.count <= index {
                    playerLayers.append(playerLayer)
                } else {
                    playerLayers[index] = playerLayer
                }
                //                let playerItem = AVPlayerItem(url: URL(string: url)!)
                //                players[index].replaceCurrentItem(with: playerItem)
                player.play()
            } else if index < players.count {
                if let videoURL = getVideoURL(for: index) {
                    let playerItem = AVPlayerItem(url: videoURL)
                    players[index].replaceCurrentItem(with: playerItem)
                    setupObserversForPlayerItem(playerItem, with: players[index])
                    print("In configure, players[\(players[index])] playerItem:\(playerItem)")
                }
            } else {
                let player = AVPlayer()
                players.append(player)
                if let currentItem = player.currentItem {
                    setupObserversForPlayerItem(currentItem, with: player)
                }
                let playerLayer = AVPlayerLayer(player: player)
                playerLayer.frame = videoViews[index].bounds
                playerLayer.videoGravity = .resizeAspectFill
                videoViews[index].layer.addSublayer(playerLayer)
                playerLayers.append(playerLayer)
            }
            print("playerLayer count:\(playerLayers.count)")
        }
        
        captureSession.sessionPreset = AVCaptureSession.Preset.hd1280x720
        guard let frontDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .front),
              let backDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else {
            print("Failed to get the camera device")
            return
        }
        
        devices.append(frontDevice)
        devices.append(backDevice)
        currentDevice = devices[0]
        guard let captureDeviceInput = try? AVCaptureDeviceInput(device: currentDevice) else {
            print("Failed to set the camera input")
            return
        }
        
        for input in captureSession.inputs {
            captureSession.removeInput(input)
        }
        if captureSession.canAddInput(captureDeviceInput) {
            captureSession.addInput(captureDeviceInput)
        }
        
        guard let audioDevice = AVCaptureDevice.default(for: .audio) else {
            print("Failed to get the audio device")
            return
        }
        
        guard let audioInput = try? AVCaptureDeviceInput(device: audioDevice) else {
            print("Failed to create audio input")
            return
        }
        
        if captureSession.canAddInput(audioInput) {
            captureSession.addInput(audioInput)
        }
        
        if videoFileOutput == nil {
            videoFileOutput = AVCaptureMovieFileOutput()
            if captureSession.canAddOutput(videoFileOutput) {
                captureSession.addOutput(videoFileOutput)
            }
        }
        cameraPreviewLayer = AVCaptureVideoPreviewLayer(session: captureSession)
        if style == 0 {
            postProductionView.isHidden = true
            if let cameraPreviewLayer = cameraPreviewLayer {
                containerView.layer.addSublayer(cameraPreviewLayer)
                cameraPreviewLayer.frame = containerView.layer.bounds
            } else {
                print("no cameraPreviewLayer")
            }
        } else if style == 1 {
            // Âú® chooseView() Áï´ cameraPreviewLayer
            postProductionView.isHidden = false
        }
        containerView.clipsToBounds = true
        cameraPreviewLayer?.videoGravity = AVLayerVideoGravity.resizeAspectFill
        
        DispatchQueue.global(qos: .background).async {
            self.captureSession.startRunning()
        }
    }
    
    @objc func toggleCameraPosition(_ sender: UIBarButtonItem) {
        guard !isRecording else {
            print("ÈåÑË£Ω‰∏≠ÔºåÁÑ°Ê≥ïÂàáÊèõÈè°È†≠")
            return
        }
        isFrontCamera.toggle()
    }
    func startRecording() {
        isRecording = true
        toggleRecordingButtons(isRecording: isRecording)
        startCountdownTimer()
        //        cameraButton.setBackgroundImage(UIImage(systemName: "stop.circle"), for: .normal)
        cameraButton.setBackgroundImage(UIImage(named: "stopButton"), for: .normal)
        if style == 0 {
            if let cameraPreviewLayer = cameraPreviewLayer {
                videoViews[0].layer.addSublayer(cameraPreviewLayer)
                cameraPreviewLayer.frame = videoViews[0].bounds
            }
        } else {
            replayVideo()
        }
        
        let outputPath = NSTemporaryDirectory() + "output\(currentRecordingIndex).mov"
        outputFileURL = URL(fileURLWithPath: outputPath)
        
        if let outputFileURL = outputFileURL {
            self.playMusic()
            videoFileOutput?.startRecording(to: outputFileURL, recordingDelegate: self)
        }
    }
    func stopCountdwonBeforeRecording() {
        timerBeforePlay?.invalidate()
        timerBeforePlay = nil
        countdownImageView.isHidden = true
        currentImageIndex = 0
    }
    func startCountdown() {
        //        countdownImageView.image = UIImage(systemName: countingImages[currentImageIndex])
        if useHandPoseStartRecording {
            if let emojiImage = UIImage.from(text: "ü§ò", font: UIFont.systemFont(ofSize: 50)) {
                countdownImageView.image = emojiImage
                countdownImageView.backgroundColor = .clear
                countdownImageView.isHidden = false
            }
        }
        timerBeforePlay = Timer.scheduledTimer(timeInterval: 1.0, target: self, selector: #selector(updateImage), userInfo: nil, repeats: true)
    }
    func toggleRecordingButtons(isRecording: Bool) {
        musicButton.isHidden = isRecording
        albumButton.isHidden = isRecording
        countdownButton.isHidden = isRecording
        cameraPositionButton.isHidden = isRecording
        handPoseButton.isHidden = isRecording
    }
    @objc func updateImage() {
        print("currentImageIndex:\(currentImageIndex)")
        if currentImageIndex < countingImages.count {
            countdownImageView.isHidden = currentImageIndex == 0
            countdownImageView.backgroundColor = .white
            countdownImageView.image = UIImage(systemName: countingImages[currentImageIndex])
        } else {
            print("invalidate")
            timerBeforePlay?.invalidate()
            timerBeforePlay = nil
            countdownImageView.isHidden = true
            startRecording()
            currentImageIndex = 0
        }
        currentImageIndex += 1
    }
    @IBAction func capture(sender: AnyObject) {
        if !isRecording { // ‰∏çÂú®ÈåÑÂΩ±ÊúâÂàÜÂÖ©Á®ÆÔºå‰∏ÄÁ®ÆÊòØÈÇÑÊ≤íÈñãÂßãÔºå‰∏ÄÁ®ÆÊòØÂÄíÊï∏Ë®àÊôÇË¢´ÂèñÊ∂àÈåÑÂΩ±
            if timerBeforePlay != nil { // ÂÄíÊï∏Ë®àÊôÇË¢´ÂèñÊ∂àÈåÑÂΩ±
                stopCountdwonBeforeRecording()
                toggleRecordingButtons(isRecording: false)
                if useHandPoseStartRecording {
                    addGestureRecognitionToSession()
                }
            } else {// ÈÇÑÊ≤íÈñãÂßã
                //                addGestureRecognitionToSession()
                if useHandPoseStartRecording {
                    disableGestureRecognition()
                }
                if countBeforeRecording { // Ë¶ÅÂÄíÊï∏Ë®àÊôÇ
                    startCountdown()
                } else { // ‰∏çË¶ÅÂÄíÊï∏Ë®àÊôÇ
                    startRecording()
                }
            }
        } else { // Ê≠£Âú®ÈåÑÂΩ±
            stopCountdownTimer()
            cameraButton.setBackgroundImage(UIImage(named: "recordingButton"), for: .normal)
            cameraButton.layer.removeAllAnimations()
            videoFileOutput?.stopRecording()
            isRecording = false
            toggleRecordingButtons(isRecording: isRecording)
        }
    }
    
    func playAllVideos() {
        if style == 0 {
            self.cameraPreviewLayer?.removeFromSuperlayer()
        } else {
            if let cameraPreviewLayer = cameraPreviewLayer {
                if !cameraPreviewLayer.isPreviewing {
                    print("isPreviewing:\(cameraPreviewLayer.isPreviewing)")
                    self.cameraPreviewLayer?.removeFromSuperlayer()
                }
            }
            if isRecording {
                adjustVolumeForRecording()
            } else {
                MPVolumeView.setVolume(playerVolume)
                print("set playerVolume:\(playerVolume)")
            }
        }
        
        videoURLs.removeAll()
        for (index, player) in players.enumerated() {
            print("index:\(index),player:\(player)")
            let playerLayer = playerLayers[index]
            if index == 1 && ensembleUserID != nil { // 1 ‰∏îÊúâÂêàÂ•èÂΩ±Áâá
                guard let url = URL(string: ensembleVideoURL!) else {
                    print("ensembleUserID ËΩâÊèõÂ§±Êïó")
                    return
                }
                videoURLs.append(url)
                let playerItem = AVPlayerItem(url: url)
                player.replaceCurrentItem(with: playerItem)
                setupObserversForPlayerItem(playerItem, with: player)
            } else {
                if let url = (index == 0 ? video0URL : video1URL) {
                    videoURLs.append(url)
                    let playerItem = AVPlayerItem(url: url)
                    player.replaceCurrentItem(with: playerItem)
                    setupObserversForPlayerItem(playerItem, with: player)
                } else {
                    if let videoURL = getVideoURL(for: index) {
                        videoURLs.append(videoURL)
                        let playerItem = AVPlayerItem(url: videoURL)
                        player.replaceCurrentItem(with: playerItem)
                        setupObserversForPlayerItem(playerItem, with: player)
                    }
                }
            }
            player.play()
            isPlaying = true
            if style == 0 {
                videoViews[0].layer.addSublayer(playerLayer)
                playerLayer.frame = videoViews[0].bounds
            } else {
                videoViews[index].layer.addSublayer(playerLayer)
                playerLayer.frame = videoViews[index].bounds
            }
            playerLayer.videoGravity = .resizeAspectFill
        }
        
        replayButton.isHidden = true
    }
    //    func getCropStartTime(for index: Int) -> CMTime? {
    //        if index == currentRecordingIndex {
    //            return videoTrim.startTime
    //        }
    //        return nil
    //    }
    func setupObserversForPlayerItem(_ playerItem: AVPlayerItem, with player: AVPlayer) {
        NotificationCenter.default.removeObserver(self, name: .AVPlayerItemDidPlayToEndTime, object: playerItem)
        NotificationCenter.default.addObserver(self, selector: #selector(videoDidEnd), name: .AVPlayerItemDidPlayToEndTime, object: playerItem)
    }
    func adjustVolumeForRecording() {
        if isHeadphoneConnected == false {
            previousVolume = playerVolume
            print("previousVolume:\(previousVolume)")
            MPVolumeView.setVolume(0.0)
            print("isRecording Volume:\(0.0)")
        } else {
            MPVolumeView.setVolume(previousVolume)
            print("set playerVolume:\(previousVolume)")
        }
    }
    func stopAllVideos() {
        for player in players {
            player.pause()
        }
        musicPlayer?.pause()
        audioPlayer?.pause()
    }
    // ÂΩ±ÁâáÊí≠ÊîæÁµêÊùü
    @objc func videoDidEnd(notification: NSNotification) {
        guard let playerItem = notification.object as? AVPlayerItem else { return }
        replayButton.isHidden = false
        containerView.bringSubviewToFront(replayButton)
        
        for (index, player) in players.enumerated() {
            if player.currentItem == playerItem {
                print("Player \(index) finished playing")
                if chooseViewButtons.count > 1 {
                    containerView.bringSubviewToFront(chooseViewButtons[index])
                    chooseViewButtons[index].isHidden = player.status == .readyToPlay && player.currentItem != nil
                    print("=======player.status:\(player.status)Ôºåplayer.currentItem==nil:\(player.currentItem == nil)")
                } else {
                    currentRecordingIndex = 0
                }
                break
            }
        }
    }
}

extension CreateViewController: AVCaptureFileOutputRecordingDelegate {
    func fileOutput(_ output: AVCaptureFileOutput, didFinishRecordingTo outputFileURL: URL, from connections: [AVCaptureConnection], error: Error?) {
        guard error == nil else {
            print(error ?? "")
            return
        }
        if captureSession.isRunning {
            captureSession.stopRunning()
        }
        playerVolume = previousVolume
        musicPlayer?.pause()
        audioPlayer?.pause()
        print("didFinishRecordingÔºåpreviousVolume:\(previousVolume)")
        
        let alertViewController = UIAlertController(title: "ÂΩ±ÁâáÈåÑË£ΩÊàêÂäüÔºü", message: "", preferredStyle: .alert)
        let successAction = UIAlertAction(title: "OK", style: .default) { _ in
            self.playAllVideos()
            self.launchTrimTopView()
        }
        let againAction = UIAlertAction(title: "Èáç‰æÜ", style: .cancel) { _ in
            if self.useHandPoseStartRecording {
                self.addGestureRecognitionToSession()
            }
            self.countdownLabel.text = self.timeFormatter(sec: self.length)
            self.clearVideoView(for: self.currentRecordingIndex)
            self.chooseView(self.chooseViewButtons[self.currentRecordingIndex])
//            self.prepareRecording(for: self.currentRecordingIndex)
        }
        alertViewController.addAction(successAction)
        alertViewController.addAction(againAction)
        present(alertViewController, animated: true)
    }
}

extension CreateViewController {
    func setupReplayButton() {
        replayButton.setBackgroundImage(UIImage(systemName: "play.circle"), for: .normal)
        replayButton.addTarget(self, action: #selector(replayVideo), for: .touchDown)
        containerView.addSubview(replayButton)
        replayButton.translatesAutoresizingMaskIntoConstraints = false
        NSLayoutConstraint.activate([
            replayButton.centerXAnchor.constraint(equalTo: containerView.centerXAnchor),
            replayButton.centerYAnchor.constraint(equalTo: containerView.centerYAnchor),
            replayButton.widthAnchor.constraint(equalToConstant: 50),
            replayButton.heightAnchor.constraint(equalToConstant: 50)
        ])
        replayButton.isHidden = true
    }
    @objc func replayVideo() {
        playAllVideos()
        for player in self.players {
            player.seek(to: .zero)
            player.play()
            replayButton.isHidden = true
        }
    }
    
    @IBAction func toggleScreenSize(sender: UIButton) {
        if style == 0 {
            if sender == stretchScreenButton {
                stretchScreenButton.isHidden = true
                shrinkScreenButton.isHidden = false
                self.containerViewLeadingConstraint.constant = 0
                self.containerViewTrailingConstraint.constant = 0
                UIView.animate(withDuration: 0.5) {
                    self.view.layoutIfNeeded()
                    self.cameraPreviewLayer?.frame = self.containerView.bounds
                }
            } else {
                stretchScreenButton.isHidden = false
                shrinkScreenButton.isHidden = true
                self.containerViewLeadingConstraint.constant = 16
                self.containerViewTrailingConstraint.constant = -16
                UIView.animate(withDuration: 0.5) {
                    self.view.layoutIfNeeded()
                }
            }
        } else if style == 1 {
            if sender == stretchScreenButton {
                stretchScreenButton.isHidden = true
                shrinkScreenButton.isHidden = false
                self.containerViewLeadingConstraint.constant = 0
                self.containerViewTrailingConstraint.constant = 0
                UIView.animate(withDuration: 0.5) {
                    self.view.layoutIfNeeded()
                    self.cameraPreviewLayer?.frame = self.videoViews[self.currentRecordingIndex].bounds
                }
            } else {
                stretchScreenButton.isHidden = false
                shrinkScreenButton.isHidden = true
                self.containerViewLeadingConstraint.constant = 16
                self.containerViewTrailingConstraint.constant = -16
                UIView.animate(withDuration: 0.5) {
                    self.view.layoutIfNeeded()
                }
            }
        }
    }
    
    func bookEarphoneState() {
        
        headphoneAlertLabel.translatesAutoresizingMaskIntoConstraints = false
        NSLayoutConstraint.activate([
            headphoneAlertLabel.topAnchor.constraint(equalTo: containerView.bottomAnchor, constant: 20),
            headphoneAlertLabel.centerXAnchor.constraint(equalTo: containerView.centerXAnchor),
            headphoneAlertLabel.heightAnchor.constraint(equalToConstant: 80),
            headphoneAlertLabel.widthAnchor.constraint(equalTo: containerView.widthAnchor)
        ])
        let route = AVAudioSession.sharedInstance().currentRoute
        for output in route.outputs {
            if output.portType == .headphones || output.portType == .bluetoothA2DP || output.portType == .airPlay || output.portType == .usbAudio || output.portType == .HDMI {
                headphoneAlertLabel.isHidden = true
                isHeadphoneConnected = true
                if previousVolume == 0 {
                    previousVolume = 0.5
                    MPVolumeView.setVolume(previousVolume)
                }
                break
            } else {
                isHeadphoneConnected = false
            }
        }
        NotificationCenter.default.addObserver(self, selector: #selector(handleRouteChange), name: AVAudioSession.routeChangeNotification, object: nil)
    }
    
    @objc func handleRouteChange(notification: Notification) {
        guard let userInfo = notification.userInfo,
              let reasonValue = userInfo[AVAudioSessionRouteChangeReasonKey] as? UInt,
              let reason = AVAudioSession.RouteChangeReason(rawValue: reasonValue) else {
            return
        }
        switch reason {
        case .newDeviceAvailable:
            let session = AVAudioSession.sharedInstance()
            let currentRoute = session.currentRoute
            for output in currentRoute.outputs {
                if output.portType == .headphones {
                    print("ËÄ≥Ê©üÂ∑≤ÈÄ£Êé•Ôºö\(output.portType.rawValue)")
                } else if output.portType == .bluetoothA2DP {
                    print("ËóçÁâôËÄ≥Ê©üÂ∑≤ÈÄ£Êé•Ôºö\(output.portType.rawValue)")
                } else if output.portType == .airPlay {
                    print("AirPlay Â∑≤ÈÄ£Êé•Ôºö\(output.portType.rawValue)")
                } else if output.portType == .usbAudio {
                    print("USB Â∑≤ÈÄ£Êé•Ôºö\(output.portType.rawValue)")
                } else if output.portType == .HDMI {
                    print("HDMI Â∑≤ÈÄ£Êé•Ôºö\(output.portType.rawValue)")
                }
            }
            headphoneAlertLabel.isHidden = true
            isHeadphoneConnected = true
        case .oldDeviceUnavailable:
            if let previousRoute = userInfo[AVAudioSessionRouteChangeReasonKey] as? AVAudioSessionRouteDescription {
                let wasUsingHeadPhones = previousRoute.outputs.contains {
                    $0.portType == .headphones
                }
                let wasUsingBlueToothEarPhones = previousRoute.outputs.contains {
                    $0.portType == .bluetoothA2DP
                }
                if wasUsingHeadPhones || wasUsingBlueToothEarPhones {
                    print("ËÄ≥Ê©üÂ∑≤ÁßªÈô§")
                    isHeadphoneConnected = false
                    headphoneAlertLabel.isHidden = false
                }
            }
            print("ÁÑ°ËÄ≥Ê©ü")
            headphoneAlertLabel.isHidden = false
            isHeadphoneConnected = false
            if isRecording {
                adjustVolume(isHeadphonesConnected: false)
            }
        default: break
        }
    }
    // Âú®ÈåÑÈü≥ÁãÄÊÖãÊîπËÆäÁ≥ªÁµ±Èü≥Èáè
    private func adjustVolume(isHeadphonesConnected: Bool) {
        for player in players {
            if isHeadphonesConnected {
                player.volume = playerVolume
                print("Headphones connected. Restoring volume.")
            } else {
                player.volume = 0
                print("Headphones disconnected. Muting audio.")
            }
        }
    }
    // style 0 ÁöÑÊ∫ñÂÇôÈåÑÂΩ±ÔºàÈÇÑ‰∏çÊòØÈåÑÂΩ±Ôºâ‰ªãÈù¢
    @objc func startToRecordingView() {
        if recordingTopView.isHidden {
            recordingTopView.isHidden = false
            updateCountdownLabel(length)
        } else {
            setupRecordingTopView()
        }
        configure(for: style)
        replayButton.isHidden = true
        postProductionView.isHidden = true
        trimView.isHidden = true
        cameraPreviewLayer?.frame = videoViews[0].bounds
        if let cameraPreviewLayer = cameraPreviewLayer {
            videoViews[0].layer.addSublayer(cameraPreviewLayer)
        } else {
            print("no cameraPreviewLayer")
        }
        chooseViewButtons[0].isHidden = true
    }
    
    @objc func chooseView(_ sender: UIButton) {
        stopAllVideos()
        print("chooseView===========recordingTopView.isHidden:\(recordingTopView.isHidden)")
        print("sender:\(sender)")
        if recordingTopView.isHidden {
            recordingTopView.isHidden = false
            updateCountdownLabel(length)
            if useHandPoseStartRecording {
                addGestureRecognitionToSession()
            }
            //            navigationController?.view.bringSubviewToFront(recordingTopView)
        } else {
            setupRecordingTopView()
        }
        configure(for: style)
        replayButton.isHidden = true
        postProductionView.isHidden = true
        trimView.isHidden = true
        let viewIndex = sender == chooseViewButtons[0] ? 0 : 1
        print("viewIndex:\(viewIndex)")
        currentRecordingIndex = viewIndex
        if let cameraPreviewLayer = cameraPreviewLayer {
            videoViews[viewIndex].layer.addSublayer(cameraPreviewLayer)
            cameraPreviewLayer.frame = videoViews[viewIndex].bounds
        } else {
            print("no cameraPreviewLayer")
        }
        chooseViewButtons[viewIndex].isHidden = true
        let otherIndex = viewIndex == 0 ? 1 : 0
        if style > 0 {
            videoViews[otherIndex].isUserInteractionEnabled = false
        }
        // Â¶ÇÊûúÊòØ style 1
        if players.count > 1 && players.count > style {
            if let currentItemOfOtherIndex = players[otherIndex].currentItem {
                if let hasContent = videoViewHasContent[otherIndex], hasContent {
                    self.chooseViewButtons[otherIndex].isHidden = hasContent
                } else {
                    self.containerView.bringSubviewToFront(self.chooseViewButtons[otherIndex])
                }
            } else {
                DispatchQueue.main.async {
                    self.chooseViewButtons[otherIndex].isHidden = false
                    self.containerView.bringSubviewToFront(self.chooseViewButtons[otherIndex])
                }
            }
        }
    }
    // ÊåâÂ∑¶‰∏äËßíx
    @objc func resetView() {
        stopCountdwonBeforeRecording()
        recordingTopView.isHidden = true
        postProductionView.isHidden = false
        trimView.isHidden = true
        cameraPreviewLayer?.removeFromSuperlayer()
        for chooseViewButton in chooseViewButtons {
            chooseViewButton.isHidden = false
        }
        if players.count > 1 {
            if let hasContent = videoViewHasContent[0], hasContent {
                chooseViewButtons[0].isHidden = true
                replayButton.isHidden = false
                if let tapGesture = videoViews[0].gestureRecognizers?.first(where: { $0 is UITapGestureRecognizer }) {
                    videoViews[0].isUserInteractionEnabled = true
                } else {
                    videoViews[0].addGestureRecognizer(tapGesture00)
                }
            }
            if let hasContent = videoViewHasContent[1], hasContent {
                chooseViewButtons[1].isHidden = true
                replayButton.isHidden = false
                if let tapGesture = videoViews[1].gestureRecognizers?.first(where: { $0 is UITapGestureRecognizer }) {
                    videoViews[1].isUserInteractionEnabled = true
                } else {
                    videoViews[1].addGestureRecognizer(tapGesture01)
                }
            }
        }
        stopAllVideos()
        playAllVideos()
    }
    @objc func pushSharePage(_ sender: UIBarButtonItem) {
        mergingAnimation()
        guard !videoURLs.isEmpty else {
            print("videoURLs Á©∫ÁöÑ")
            let alert = UIAlertController(title: "Ë´ãÂÖàÈåÑÂΩ±", message: "ÈªûÊìä + ÈçµÈñãÂßãÈåÑË£Ω", preferredStyle: .alert)
            alert.addAction(UIAlertAction(title: "OK", style: .cancel))
            present(alert, animated: true, completion: nil)
            return
        }
        guard let outputFileURL = outputFileURL, let duration = duration/*, let ensembleUserID = ensembleUserID*/ else {
            print("ÈªûÊìäÂàÜ‰∫´ÈçµÔºå‰ΩÜËº∏Âá∫Â§±Êïó")
            let alert = UIAlertController(title: "ËÉåÊôØËº∏Âá∫‰∏≠", message: "Ë´ãÁ®çÁ≠âÁâáÂàªÔºåÂÜçÂòóË©¶ÂàÜ‰∫´", preferredStyle: .alert)
            alert.addAction(UIAlertAction(title: "OK", style: .cancel))
            present(alert, animated: true, completion: nil)
            return
        }
        let outputMergedFileURL = URL(fileURLWithPath: NSTemporaryDirectory() + "mergedOutput.mov")
        if style > 0 {
            mergeMedia(videoURLs: videoURLs, audioURLs: audioURLs, outputURL: outputMergedFileURL) { [weak self] success in
                DispatchQueue.main.async {
                    if success {
                        let shareVC = ShareViewController()
                        shareVC.url = outputMergedFileURL
                        shareVC.duration = duration
                        if let ensembleUserID = self?.ensembleUserID {
                            shareVC.ensembleUserID = ensembleUserID
                        }
                        print("Â∞éÂá∫ÊàêÂäüÔºåÂª∫Á´ã‰∏¶Êé®ÈÄÅ ShareViewController")
                        self?.navigationController?.pushViewController(shareVC, animated: true)
                    } else {
                        let alert = UIAlertController(title: "Â∞éÂá∫ÈåØË™§", message: "ÁÑ°Ê≥ïÂ∞éÂá∫ÂΩ±Áâá", preferredStyle: .alert)
                        alert.addAction(UIAlertAction(title: "Á¢∫ÂÆö", style: .default))
                        self?.present(alert, animated: true, completion: nil)
                    }
                }
            }
        } else {
            let shareVC = ShareViewController()
            shareVC.url = outputFileURL
            shareVC.duration = duration
            navigationController?.pushViewController(shareVC, animated: true)
        }
    }
    func mergingAnimation() {
        
        if animView == nil {
            animView = LottieAnimationView(name: "Animation02", bundle: .main)
            guard let animView = animView else {
                print("AnimView doesn't work.")
                return
            }
            animView.frame = CGRect(x: 200, y: 350, width: 300, height: 300)
            animView.center = self.view.center
            animView.loopMode = .loop
            animView.animationSpeed = 1
            self.view.addSubview(animView)
            let label = UILabel(frame: CGRect(x: Int(animView.bounds.minX + 50), y: Int(animView.bounds.midY), width: 200, height: 30))
            label.attributedText = attributedTextForm(content: "Video Processing...", size: 20, kern: 0, color: .white)
            label.textColor = .white
            animView.addSubview(label)
            animView.bringSubviewToFront(animView)
        }
        animView?.play()
    }
    func getVideoURL(for index: Int) -> URL? {
        let outputPath = NSTemporaryDirectory() + "output\(index).mov"
        outputFileURL = URL(fileURLWithPath: outputPath)
        return outputFileURL
    }
    
    func configurePlayersAndAddObservers() {
        guard !players.isEmpty else {
            return
        }
        for player in players {
            if let currentItem = player.currentItem {
                NotificationCenter.default.addObserver(forName: .AVPlayerItemDidPlayToEndTime, object: currentItem, queue: .main) { [weak self] notification in
                    self?.videoDidEnd(notification: notification as NSNotification)
                }
            }
        }
    }
    
    func clearTemporaryVideos() {
        let fileManager = FileManager.default
        let tempDirectoryPath = NSTemporaryDirectory()
        
        do {
            let tempFiles = try fileManager.contentsOfDirectory(atPath: tempDirectoryPath)
            for file in tempFiles {
                let filePath = (tempDirectoryPath as NSString).appendingPathComponent(file)
                try fileManager.removeItem(atPath: filePath)
            }
        } catch let error {
            print("Failed to clear temporary files: \(error)")
        }
    }
    private func configureSessionWithNewInput(_ newInput: AVCaptureDeviceInput) {
        captureSession.beginConfiguration()
        
        for input in captureSession.inputs {
            if let deviceInput = input as? AVCaptureDeviceInput, deviceInput.device.hasMediaType(.video) {
                captureSession.removeInput(deviceInput)
            }
        }
        
        if captureSession.canAddInput(newInput) {
            captureSession.addInput(newInput)
        } else {
            print("Can't add new video input to the session.")
        }
        
        captureSession.commitConfiguration()
        
        if !captureSession.isRunning {
            captureSession.startRunning()
        }
    }
    func mergeMedia(videoURLs: [URL], audioURLs: [URL], outputURL: URL, completion: @escaping (Bool) -> Void) {
        let mixComposition = AVMutableComposition()
        var instructions = [AVMutableVideoCompositionLayerInstruction]()
        var videoFrames = [CGRect]()
        if Thread.isMainThread {
            for videoView in self.videoViews {
                videoFrames.append(videoView.frame)
                print("===videoView.frame:\(videoView.frame)")
            }
        } else {
            DispatchQueue.main.sync {
                for videoView in self.videoViews {
                    videoFrames.append(videoView.frame)
                }
            }
        }
        let dispatchGroup = DispatchGroup()
        for (index, videoURL) in videoURLs.enumerated() {
            print("videoURLs.count:\(videoURLs.count)")
            print("index:\(index),videoURL:\(videoURL)")
            dispatchGroup.enter()
            let videoAsset = AVURLAsset(url: videoURL)
            guard let videoTrack = videoAsset.tracks(withMediaType: .video).first,
                  let audioTrack = videoAsset.tracks(withMediaType: .audio).first else {
                continue
            }
            print("Video Track Count: \(videoAsset.tracks(withMediaType: .video).count)")
            print("Audio Track Count: \(videoAsset.tracks(withMediaType: .audio).count)")
            videoAsset.loadTracks(withMediaType: .video) { tracks, error in
                
                guard let videoTrack = tracks?.first
                else {
                    dispatchGroup.leave()
                    return
                }
                print("videoTrack:\(videoTrack)")
                print("Preferred Transform: \(videoTrack.preferredTransform)")
                
                do {
                    if let compositionVideoTrack = mixComposition.addMutableTrack(withMediaType: .video, preferredTrackID: kCMPersistentTrackID_Invalid) {
                        print("Video track added successfully.")
                        try compositionVideoTrack.insertTimeRange(CMTimeRange(start: .zero, duration: videoAsset.duration), of: videoTrack, at: .zero)
                        if let compositionAudioTrack = mixComposition.addMutableTrack(withMediaType: .audio, preferredTrackID: kCMPersistentTrackID_Invalid) {
                            try? compositionAudioTrack.insertTimeRange(CMTimeRange(start: .zero, duration: videoAsset.duration), of: audioTrack, at: .zero)
                        }
                        let layerInstruction = AVMutableVideoCompositionLayerInstruction(assetTrack: compositionVideoTrack)
                        let preferredTransform = videoTrack.preferredTransform
                        let videoSize = videoTrack.naturalSize
                        print("videoSize:\(videoSize)") // (1280, 720)
                        let videoFrame = videoFrames[index] // (0.0, 0.0, 170.5, 343.0), (172.5, 0.0, 170.5, 343.0)
                        let scaleToFitRatioWidth = videoFrame.size.width / videoSize.height
                        print("index:\(index),scaleToFitRatioWidth:\(scaleToFitRatioWidth)")
                        let scaleToFitRatioHeight = videoFrame.size.height / videoSize.width
                        print("index:\(index),scaleToFitRatioHeight:\(scaleToFitRatioHeight)")
                        let undoTranslation = CGAffineTransform(translationX: -videoSize.height, y: 0)
                        let transformWithUndoTranslation = preferredTransform.concatenating(undoTranslation)
                        let scaleFactor = CGAffineTransform(scaleX: scaleToFitRatioWidth, y: scaleToFitRatioHeight)
                        let transformWithScale = transformWithUndoTranslation.concatenating(scaleFactor)
                        print("index:\(index), transformWithScale:\(transformWithScale)")
                        
                        var translation = CGAffineTransform(translationX: CGFloat(index) * videoFrame.origin.x + videoFrame.width + 2, y: videoFrame.origin.y)
                        if index == 0 {
                        } else {
                            translation.tx += 0.5
                        }
                        print("index:\(index), translation:\(translation)")
                        let finalTransform = transformWithScale.concatenating(translation)
                        print("index:\(index),finalTransform:\(finalTransform)")
                        layerInstruction.setTransform(finalTransform, at: .zero)
                        print("index:\(index),layerInstruction:\(layerInstruction)")
                        instructions.append(layerInstruction)
                        print("Current number of layerInstructions: \(instructions.count)")
                        print("Scale to fit ratio (Width): \(scaleToFitRatioWidth), (Height): \(scaleToFitRatioHeight)")
                        print("Transform applied: \(transformWithScale)")
                        print("Translation applied: \(translation)")
                        print("Final Transform: \(finalTransform)")
                    } else {
                        print("Failed to add video track.")
                    }
                } catch {
                    print("Error with inserting video into composition: \(error)")
                }
                dispatchGroup.leave()
            }
        }
        dispatchGroup.notify(queue: .main) {
            print("Final instructions count: \(instructions.count)")
            let mainInstruction = AVMutableVideoCompositionInstruction()
            mainInstruction.timeRange = CMTimeRange(start: .zero, duration: mixComposition.duration)
            mainInstruction.layerInstructions = instructions
            
            print("Final video composition instructions: \(mainInstruction.layerInstructions)")
            let videoComposition = AVMutableVideoComposition()
            videoComposition.renderSize = CGSize(width: self.containerView.frame.width, height: self.containerView.frame.height)
            print("videoComposition.renderSize: \(videoComposition.renderSize)")
            print("videoComposition.frame:\(videoComposition)")
            videoComposition.frameDuration = CMTime(value: 1, timescale: 30) // ÂπÄÁéá
            videoComposition.instructions = [mainInstruction]
            guard let exporter = AVAssetExportSession(asset: mixComposition, presetName: AVAssetExportPresetHighestQuality) else {
                print("ÁÑ°Ê≥ïÂâµÂª∫ ExportSession")
                completion(false)
                return
            }
            exporter.outputURL = outputURL
            exporter.outputFileType = .mov
            exporter.videoComposition = videoComposition
            print("exporter:\(exporter)")
            print("exporter.videoComposition:\(exporter.videoComposition)")
            exporter.exportAsynchronously {
                DispatchQueue.main.async {
                    print("Export Status: \(exporter.status)")
                    print("Export Session Error: \(String(describing: exporter.error))")
                    switch exporter.status {
                    case .completed:
                        print("Â∞éÂá∫ÂÆåÊàê")
                        completion(true)
                    case .failed:
                        print("Â∞éÂá∫Â§±ÊïóÔºö\(exporter.error?.localizedDescription ?? "Êú™Áü•ÈåØË™§")")
                        completion(false)
                    default:
                        print("Â∞éÂá∫Êú™ÂÆåÊàê")
                        completion(false)
                    }
                }
            }
        }
    }
    func getCurrentSystemVolume() {
        let audioSession = AVAudioSession.sharedInstance()
        do {
            try audioSession.setActive(true)
        } catch {
            print("Unable to activate audio session")
        }
        playerVolume = audioSession.outputVolume
        print("Current system volume: \(playerVolume)")
        audioSession.addObserver(self, forKeyPath: "outputVolume", options: NSKeyValueObservingOptions.new, context: nil)
    }
    
    override func observeValue(forKeyPath keyPath: String?, of object: Any?, change: [NSKeyValueChangeKey: Any]?, context: UnsafeMutableRawPointer?) {
        if keyPath == "outputVolume", let volumeChange = change?[.newKey] as? Float {
            playerVolume = volumeChange
            print("playerVolume: \(playerVolume)")
            return
        }
        super.observeValue(forKeyPath: keyPath, of: object, change: change, context: context)
    }
}

extension MPVolumeView {
    static func setVolume(_ volume: Float) {
        let volumeView = MPVolumeView()
        let slider = volumeView.subviews.first(where: { $0 is UISlider }) as? UISlider
        
        DispatchQueue.main.asyncAfter(deadline: DispatchTime.now() + 0.01) {
            slider?.value = volume
        }
    }
}
extension CreateViewController {
    private func updateTrimTime() {
        for (index, player) in players.enumerated() {
            if let currentItem = player.currentItem {
                let startTime = trimView.videoTrim.startTime
                let endTime = trimView.videoTrim.endTime
                let timeRange = CMTimeRange(start: startTime, end: endTime)
                currentItem.seek(to: startTime, completionHandler: nil)
                print("Êõ¥Êñ∞Á¨¨ \(index) ÂÄãÊí≠ÊîæÂô®ÁöÑÊí≠ÊîæÁØÑÂúçÁÇ∫ \(timeRange)")
            }
        }
    }
}
extension CreateViewController: VideoTrimDelegate {
    func videoTrimStartTrimChange(_ view: VideoTrim) {
        isPlaying = false
        self.stopAllVideos()
    }
    
    func videoTrimEndTrimChange(_ view: VideoTrim) {
        let startTime = view.startTime
        let endTime = view.endTime
        updatePlayerRange(for: players[currentRecordingIndex], withStartTime: startTime, endTime: endTime)
    }
    
    func updatePlayerRange(for player: AVPlayer, withStartTime startTime: CMTime, endTime: CMTime) {
        guard let currentItem = player.currentItem else {
            return
        }
        let asset = currentItem.asset
        
        let duration = CMTimeSubtract(endTime, startTime)
        if CMTimeCompare(duration, .zero) <= 0 {
            print("ÁµêÊùüÊôÇÈñìÂøÖÈ†àÂ§ßÊñºÈñãÂßãÊôÇÈñì")
            return
        }
        //        let newRange = CMTimeRange(start: startTime, duration: duration)
        let newPlayerItem = AVPlayerItem(asset: asset)
        newPlayerItem.forwardPlaybackEndTime = endTime
        player.replaceCurrentItem(with: newPlayerItem)
        player.seek(to: startTime, toleranceBefore: .zero, toleranceAfter: .zero) { _ in
            player.play()
        }
    }
    
    func videoTrimPlayTimeChange(_ view: VideoTrim) {
        let newTime = CMTime(value: CMTimeValue(view.playTime.value + view.startTime.value), timescale: view.playTime.timescale)
        let player = players[currentRecordingIndex]
        player.seek(to: newTime, toleranceBefore: .zero, toleranceAfter: .zero)
    }
    
    func setupEndTimeObserver(for player: AVPlayer, startTime: CMTime, endTime: CMTime) {
        if let observer = endTimeObservers[player] {
            player.removeTimeObserver(observer)
            endTimeObservers[player] = nil
        }
        
        let observer = player.addPeriodicTimeObserver(forInterval: CMTime(seconds: 1, preferredTimescale: 1), queue: .global()) { [weak self] time in
            if time >= endTime {
                DispatchQueue.main.async {
                    self?.stopAllVideos()
                    player.seek(to: startTime)
                }
            }
        }
        endTimeObservers[player] = observer
    }
    func exportCroppedVideo(asset: AVAsset, startTime: CMTime, endTime: CMTime, outputURL: URL, completion: @escaping (Bool) -> Void) {
        print("asset.tracks:\(asset.tracks)")
        guard asset.tracks(withMediaType: .video).first != nil else {
            print("Â∞éÂá∫Â§±Êïó: Ê≤íÊúâÊâæÂà∞ video track")
            completion(false)
            return
        }
        
        guard let exportSession = AVAssetExportSession(asset: asset, presetName: AVAssetExportPresetHighestQuality) else {
            print("Â∞éÂá∫Â§±Êïó: ÁÑ°Ê≥ïÂâµÂª∫ exportSession")
            completion(false)
            return
        }
        
        exportSession.outputURL = outputURL
        exportSession.outputFileType = .mov
        exportSession.timeRange = CMTimeRange(start: startTime, end: endTime)
        exportSession.exportAsynchronously {
            DispatchQueue.main.async {
                switch exportSession.status {
                case .completed:
                    print("Ë£ÅÂâ™ÂíåÂ∞éÂá∫ÊàêÂäüÔºåÊñá‰ª∂Â∑≤Êõ¥Êñ∞")
                    completion(true)
                case .failed:
                    print("Â∞éÂá∫Â§±Êïó: \(exportSession.error?.localizedDescription ?? "Êú™Áü•ÈåØË™§")")
                    completion(false)
                case .cancelled:
                    print("Â∞éÂá∫ÂèñÊ∂à")
                    completion(false)
                default:
                    print("Â∞éÂá∫ÁãÄÊÖãÊú™Áü•")
                    completion(false)
                }
            }
        }
    }
    @objc func clearVideoView(for index: Int) {
        if style == 0 {
            replayButton.isHidden = true
        } else {
            let otherIndex = index == 0 ? 1 : 0
            if let hasContent = videoViewHasContent[otherIndex], hasContent {
                replayButton.isHidden = false
            } else {
                replayButton.isHidden = true
            }
        }
        print("=====status of replayButton isHidden: \(replayButton.isHidden)==========")
        if let tapGesture = videoViews[index].gestureRecognizers?.first(where: { $0 is UITapGestureRecognizer }) {
                videoViews[index].removeGestureRecognizer(tapGesture)
        }
        let player = players[index]
        stopAllVideos()
        player.replaceCurrentItem(with: nil)
        print("index: \(index), currentItem: \(player.currentItem ?? nil)")
        playerLayers[index].removeFromSuperlayer()
        if let url = getVideoURL(for: index) {
            do {
                try FileManager.default.removeItem(at: url)
                print("ÊàêÂäüÊ∏ÖÈô§ÂΩ±ÁâáÊ™îÊ°à")
                self.videoViewHasContent[index] = false
                print(" self.videoViewHasContent[self.currentRecordingIndex] :\(self.videoViewHasContent[self.currentRecordingIndex] )")
            } catch {
                print("Ê∏ÖÈô§ÂΩ±ÁâáÊ™îÊ°àÂ§±Êïó: \(error)")
            }
        } else if index == 0 {
            if let url = video0URL {
                do {
                    try FileManager.default.removeItem(at: url)
                    print("ÊàêÂäüÊ∏ÖÈô§ÂΩ±ÁâáÊ™îÊ°à")
                    self.videoViewHasContent[index] = false
                } catch {
                    print("Ê∏ÖÈô§ÂΩ±ÁâáÊ™îÊ°àÂ§±Êïó: \(error)")
                }
            }
        } else if index == 1 {
            if let url = video1URL {
                do {
                    try FileManager.default.removeItem(at: url)
                    print("ÊàêÂäüÊ∏ÖÈô§ÂΩ±ÁâáÊ™îÊ°à")
                    self.videoViewHasContent[index] = false
                } catch {
                    print("Ê∏ÖÈô§ÂΩ±ÁâáÊ™îÊ°àÂ§±Êïó: \(error)")
                }
            }
        } else {
            self.videoViewHasContent[index] = false
        }
        print("clearViewView videoViewHasContent- index:\(index), videoViewHasContent:\(self.videoViewHasContent[index])")
        videoViews[index].subviews.forEach { subview in
            if let button = subview as? UIButton, chooseViewButtons.contains(button) {
                button.isHidden = false
            }
        }
    }
    // Âà™Èô§ÈáçÈåÑÂõûÂà∞Êúâ+ÁöÑÁï´Èù¢
    @objc func prepareRecording(for index: Int) {
        //        configure(for: style)
        chooseViewButtons[index].isHidden = false
    }
    @IBAction func selectMusic(_ sender: Any) {
        recordingTopView.isHidden = true
        stopCountdownTimer()
        disableGestureRecognition()
        let controller = MusicViewController()
        //        controller.modalPresentationStyle = .fullScreen
        controller.view.backgroundColor = UIColor.black.withAlphaComponent(0.5)
        controller.modalPresentationStyle = .overCurrentContext
        controller.delegate = self
        present(controller, animated: true)
    }
}

extension CreateViewController: PHPickerViewControllerDelegate {
    @IBAction func selectVideo(_ sender: Any) {
        stopCountdownTimer()
        disableGestureRecognition()
        var configuration = PHPickerConfiguration()
        configuration.filter = .videos
        let picker = PHPickerViewController(configuration: configuration)
        picker.delegate = self
        present(picker, animated: true)
    }
    
    func picker(_ picker: PHPickerViewController, didFinishPicking results: [PHPickerResult]) {
        guard let provider = results.first?.itemProvider, provider.hasItemConformingToTypeIdentifier(UTType.movie.identifier) else {
            picker.dismiss(animated: true)
            return
        }
        if provider.hasItemConformingToTypeIdentifier(UTType.movie.identifier) {
            provider.loadItem(forTypeIdentifier: UTType.movie.identifier, options: nil) { (item, error) in
                guard let url = item as? URL,
                        error == nil else {
                    print("Error: \(error?.localizedDescription ?? "Unknown error")")
                    return
                }
            }
        } else {
            picker.dismiss(animated: true)
        }
        provider.loadFileRepresentation(forTypeIdentifier: UTType.movie.identifier) { url, error in
            guard let url = url, error == nil else {
                print("Error: \(error?.localizedDescription ?? "Unknown error")")
                return
            }
            let sandboxURL = FileManager.default.temporaryDirectory.appendingPathComponent(url.lastPathComponent)
            do {
                if FileManager.default.fileExists(atPath: sandboxURL.path) {
                    try FileManager.default.removeItem(at: sandboxURL)
                }
                try FileManager.default.copyItem(at: url, to: sandboxURL)
                /* try FileManager.default.copyItem(at: url, to: URL(fileURLWithPath: NS*//*TemporaryDirectory() + "output\(self.currentRecordingIndex).mov"))*/
                DispatchQueue.main.async {
                    if self.currentRecordingIndex == 0 {
                        self.video0URL = sandboxURL
                    } else {
                        self.video1URL = sandboxURL
                    }
                    picker.dismiss(animated: true) {
                        self.playAllVideos()
                        self.launchTrimTopView()
                        if self.useHandPoseStartRecording {
                            self.addGestureRecognitionToSession()
                        }
                    }
                }
            } catch {
                print("Ê™îÊ°àÁÆ°ÁêÜÈåØË™§: \(error)")
            }
        }
    }
    // Ë®≠ÂÆöÁõ∏Á∞øËº∏ÂÖ•ÂΩ±ÁâáÁöÑÊí≠ÊîæÂô®
    func setupPlayer(with url: URL) {
        recordingTopView.isHidden = false
        replayButton.isHidden = true
        if style == 0 {
            self.cameraPreviewLayer?.removeFromSuperlayer()
        } else {
            if let cameraPreviewLayer = cameraPreviewLayer {
                if cameraPreviewLayer.isPreviewing {
                    print("isPreviewing:\(cameraPreviewLayer.isPreviewing)")
                    self.cameraPreviewLayer?.removeFromSuperlayer()
                }
            }
            if isRecording {
                adjustVolumeForRecording()
            } else {
                MPVolumeView.setVolume(playerVolume)
                print("set playerVolume:\(playerVolume)")
            }
        }
        if style == 1 && ensembleVideoURL != nil {
            videoURLs.insert(url, at: 0)
            players[0] = AVPlayer(url: url)
            playerLayers[0] = AVPlayerLayer(player: players[currentRecordingIndex])
            playerLayers[0].frame = videoViews[currentRecordingIndex].bounds
            videoViews[0].layer.addSublayer(playerLayers[currentRecordingIndex])
            playerLayers[0].videoGravity = .resizeAspectFill
            NotificationCenter.default.addObserver(
                self,
                selector: #selector(videoDidEnd(notification:)),
                name: .AVPlayerItemDidPlayToEndTime,
                object: players[0].currentItem
            )
        } else {
            videoURLs.append(url)
            players[currentRecordingIndex] = AVPlayer(url: url)
            playerLayers[currentRecordingIndex] = AVPlayerLayer(player: players[currentRecordingIndex])
            playerLayers[currentRecordingIndex].frame = videoViews[currentRecordingIndex].bounds
            videoViews[currentRecordingIndex].layer.addSublayer(playerLayers[currentRecordingIndex])
            playerLayers[currentRecordingIndex].videoGravity = .resizeAspectFill
        }
        
        launchTrimTopView()
        for player in self.players {
            player.seek(to: CMTime.zero)
            player.play()
        }
    }
}
extension CreateViewController: MusicSelectionDelegate {
    func musicViewController(_ controller: MusicViewController, didSelectMusic music: MusicType) {
        selectedMusic = music
    }
    
    func playMusic() {
        guard let selectedMusic = selectedMusic else {
            print("No music selected")
            return
        }
        
        switch selectedMusic {
        case .mp3(let url):
            do {
                let audioPlayer = try AVAudioPlayer(contentsOf: url)
                audioPlayer.play()
                self.audioPlayer = audioPlayer
            } catch {
                print("Failed to play music from file: \(error)")
            }
        case .appleMusic(let id):
            requestMediaLibraryAccess(id: id)
            print("Apple Music ID: \(id)")
        }
    }
    func requestMediaLibraryAccess(id: String) {
        MPMediaLibrary.requestAuthorization { status in
            if status == .authorized {
                if let id = UInt64(id) {
                    self.fetchMediaItem(usingPersistentID: id)
                }
                
            } else {
                print("Access denied by the user")
            }
        }
    }
    func fetchMediaItem(usingPersistentID persistentID: UInt64) {
        let query = MPMediaQuery()
        let predicate = MPMediaPropertyPredicate(value: persistentID, forProperty: MPMediaItemPropertyPersistentID)
        query.addFilterPredicate(predicate)
        
        if let items = query.items, let item = items.first {
            let collection = MPMediaItemCollection(items: [item])
            playMediaItemCollection(collection)
        } else {
            print("No items found")
        }
    }
    func playMediaItemCollection(_ collection: MPMediaItemCollection) {
        musicPlayer = MPMusicPlayerController.systemMusicPlayer // .applicationMusicPlayer
        musicPlayer?.setQueue(with: collection)
        musicPlayer?.play()
    }
}
